{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "red_wine = pd.read_csv('https://query.data.world/s/rrj4d2f6sj2apz4x7sozpd6epmrsiy')\n",
    "white_wine = pd.read_csv('https://query.data.world/s/brho7trfnuy4iz2nxraqzsfwvgek5b')\n",
    "\n",
    "high_quality = white_wine.loc[ white_wine['quality'] > 6 ]   #ratings 9, 8, 7 only, 1060 rows\n",
    "mid_quality_initial = white_wine.loc[ white_wine['quality'] < 7 ]\n",
    "mid_quality = mid_quality_initial.loc[ mid_quality_initial['quality'] > 4 ]   #ratings 5, 6 only, 3655 rows\n",
    "low_quality = white_wine.loc[ white_wine['quality'] < 5 ]   #ratings 3, 4 only, 183 rows\n",
    "mid_and_low_quality = white_wine.loc[ white_wine['quality'] < 7 ]   #ratings 3, 4, 5, 6 only, 3838 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a k value = 2 : \n",
      "[[  1   0   2   1   1   0   0]\n",
      " [  2   9   9   4   1   0   0]\n",
      " [  2  11 205  69   3   1   0]\n",
      " [  0  17 165 212  32   6   0]\n",
      " [  2   8  40  81  59   2   0]\n",
      " [  0   1   4  18   8   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 490.\n",
      "For a k value = 3 : \n",
      "[[  1   0   2   1   1   0   0]\n",
      " [  2   3  11   7   2   0   0]\n",
      " [  1  12 156  97  21   4   0]\n",
      " [  0  11 137 221  53  10   0]\n",
      " [  0  10  40  69  66   7   0]\n",
      " [  0   1   4  17   6   7   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 454.\n",
      "For a k value = 4 : \n",
      "[[  1   0   3   0   1   0   0]\n",
      " [  1   0  14   8   2   0   0]\n",
      " [  0   7 172  87  22   3   0]\n",
      " [  0   5 128 240  49  10   0]\n",
      " [  0   3  35  87  61   6   0]\n",
      " [  0   1   2  19   7   6   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 480.\n",
      "For a k value = 5 : \n",
      "[[  0   0   4   1   0   0   0]\n",
      " [  1   2  13   7   2   0   0]\n",
      " [  0   6 149 116  19   1   0]\n",
      " [  0   5 112 261  50   4   0]\n",
      " [  0   3  44  89  51   5   0]\n",
      " [  0   0   1  21   9   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 467.\n",
      "For a k value = 6 : \n",
      "[[  0   0   4   1   0   0   0]\n",
      " [  1   3  12   7   2   0   0]\n",
      " [  0   4 161 107  18   1   0]\n",
      " [  0   5 129 253  43   2   0]\n",
      " [  0   4  44  92  48   4   0]\n",
      " [  0   0   2  21   8   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 469.\n",
      "For a k value = 7 : \n",
      "[[  0   0   3   2   0   0   0]\n",
      " [  0   5  10   8   2   0   0]\n",
      " [  0   3 140 124  21   3   0]\n",
      " [  0   4 105 272  49   2   0]\n",
      " [  0   2  34 102  49   5   0]\n",
      " [  0   0   3  24   6   2   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 468.\n"
     ]
    }
   ],
   "source": [
    "#Knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "ks = [2,3,4,5,6,7]\n",
    "\n",
    "for k in ks:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"For a k value = \" + str(k) + \" : \")\n",
    "    print(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))\n",
    "    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a k value = 2 : \n",
      "[[  0   2   2   1   0   0   0]\n",
      " [  2   5   8   7   2   1   0]\n",
      " [  1  20 202  58   9   1   0]\n",
      " [  3  23 149 225  30   2   0]\n",
      " [  0  18  30  83  59   2   0]\n",
      " [  0   1   3  16   8   7   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 498.\n",
      "For a k value = 3 : \n",
      "[[  0   0   2   3   0   0   0]\n",
      " [  2   3   9   5   5   1   0]\n",
      " [  1  15 154 103  17   1   0]\n",
      " [  1  22 106 243  55   5   0]\n",
      " [  0  15  28  66  79   4   0]\n",
      " [  0   0   1  15  11   8   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 487.\n",
      "For a k value = 4 : \n",
      "[[  0   0   3   2   0   0   0]\n",
      " [  1   2  10   9   3   0   0]\n",
      " [  0   8 168  93  20   2   0]\n",
      " [  1  12 118 252  44   5   0]\n",
      " [  0   4  24  87  74   3   0]\n",
      " [  0   0   2  14  12   7   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 503.\n",
      "For a k value = 5 : \n",
      "[[  0   0   3   2   0   0   0]\n",
      " [  1   1   7  11   5   0   0]\n",
      " [  0   7 172 100  12   0   0]\n",
      " [  0   5 118 264  40   5   0]\n",
      " [  0   3  24  96  67   2   0]\n",
      " [  0   0   1  19  12   3   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 507.\n",
      "For a k value = 6 : \n",
      "[[  0   0   3   2   0   0   0]\n",
      " [  0   0   9  14   2   0   0]\n",
      " [  0   6 178  91  16   0   0]\n",
      " [  0   2 117 265  43   5   0]\n",
      " [  0   2  20 107  63   0   0]\n",
      " [  0   1   3  17  11   3   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 509.\n",
      "For a k value = 7 : \n",
      "[[  0   0   3   2   0   0   0]\n",
      " [  0   0   8  15   2   0   0]\n",
      " [  0   3 170 101  17   0   0]\n",
      " [  0   1 104 281  42   4   0]\n",
      " [  0   1  23 108  59   1   0]\n",
      " [  0   1   3  17  10   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 514.\n"
     ]
    }
   ],
   "source": [
    "#knn classification taking features that seem to be strong high quality indicators\n",
    "X = X_initial[ ['alcohol', 'density'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "ks = [2,3,4,5,6,7]\n",
    "\n",
    "for k in ks:    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"For a k value = \" + str(k) + \" : \")\n",
    "    print(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))\n",
    "    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a k value = 2 : \n",
      "[[  1   0   2   2   0   0   0]\n",
      " [  1   8   8   8   0   0   0]\n",
      " [  3  16 186  72  12   2   0]\n",
      " [  2  24 164 219  21   2   0]\n",
      " [  0   3  79  69  41   0   0]\n",
      " [  0   0  12  11   8   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 459.\n",
      "For a k value = 3 : \n",
      "[[  0   0   3   1   1   0   0]\n",
      " [  1   3  11   9   1   0   0]\n",
      " [  3  14 145 102  22   5   0]\n",
      " [  1  16 122 247  44   2   0]\n",
      " [  0   1  72  65  52   2   0]\n",
      " [  0   0  13  12   5   5   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 452.\n",
      "For a k value = 4 : \n",
      "[[  1   0   2   1   1   0   0]\n",
      " [  1   2  14   7   1   0   0]\n",
      " [  0   8 149 108  25   1   0]\n",
      " [  1   7 127 260  33   4   0]\n",
      " [  0   2  69  73  46   2   0]\n",
      " [  0   0  12  14   4   5   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 463.\n",
      "For a k value = 5 : \n",
      "[[  1   0   3   1   0   0   0]\n",
      " [  1   3  14   7   0   0   0]\n",
      " [  0   9 137 126  18   1   0]\n",
      " [  0   8 134 257  28   5   0]\n",
      " [  0   2  70  81  38   1   0]\n",
      " [  0   0  10  16   6   3   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 439.\n",
      "For a k value = 6 : \n",
      "[[  1   0   1   2   1   0   0]\n",
      " [  1   3  12   9   0   0   0]\n",
      " [  0   8 138 120  24   1   0]\n",
      " [  0  10 127 264  28   3   0]\n",
      " [  0   3  72  81  35   1   0]\n",
      " [  0   1  12  14   5   3   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 444.\n",
      "For a k value = 7 : \n",
      "[[  1   0   1   2   1   0   0]\n",
      " [  1   3  12   8   1   0   0]\n",
      " [  0   7 137 119  27   1   0]\n",
      " [  0   9 127 262  33   1   0]\n",
      " [  0   1  61  91  37   2   0]\n",
      " [  0   0  11  17   4   3   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 443.\n"
     ]
    }
   ],
   "source": [
    "#knn classification taking features that seem to be strong low quality indicators\n",
    "X = X_initial[ ['free sulfur dioxide', 'volatile acidity', 'fixed acidity'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "ks = [2,3,4,5,6,7]\n",
    "\n",
    "for k in ks:    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"For a k value = \" + str(k) + \" : \")\n",
    "    print(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))\n",
    "    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a k value = 2 : \n",
      "[[  0   0   3   1   1   0   0]\n",
      " [  0   2  11  11   1   0   0]\n",
      " [  0  27 173  75  15   1   0]\n",
      " [  3  24 171 199  28   7   0]\n",
      " [  3  10  42  86  47   4   0]\n",
      " [  0   1   7  15   9   3   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 424.\n",
      "For a k value = 3 : \n",
      "[[  0   0   2   1   2   0   0]\n",
      " [  0   2   9  12   2   0   0]\n",
      " [  2  23 126 115  22   3   0]\n",
      " [  2  20 141 218  43   8   0]\n",
      " [  3  11  37  73  62   6   0]\n",
      " [  0   1   8  12  10   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 412.\n",
      "For a k value = 4 : \n",
      "[[  0   0   2   2   1   0   0]\n",
      " [  0   1  10  10   3   1   0]\n",
      " [  0  13 147 109  18   4   0]\n",
      " [  0  12 142 230  43   5   0]\n",
      " [  0   6  35  94  52   5   0]\n",
      " [  0   1   7  12  11   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 434.\n",
      "For a k value = 5 : \n",
      "[[  0   0   2   2   1   0   0]\n",
      " [  0   0  10  11   4   0   0]\n",
      " [  0   6 138 130  13   4   0]\n",
      " [  1   6 134 254  33   4   0]\n",
      " [  0   0  32 105  49   6   0]\n",
      " [  0   0   6  15  10   4   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 445.\n",
      "For a k value = 6 : \n",
      "[[  0   0   4   1   0   0   0]\n",
      " [  0   1  10  12   2   0   0]\n",
      " [  0   3 137 138  11   2   0]\n",
      " [  0   5 146 242  35   4   0]\n",
      " [  0   0  33 103  52   4   0]\n",
      " [  0   0   7  18   8   2   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 434.\n",
      "For a k value = 7 : \n",
      "[[  0   0   3   2   0   0   0]\n",
      " [  0   1  10  11   2   1   0]\n",
      " [  0   1 129 148  12   1   0]\n",
      " [  0   4 129 259  38   2   0]\n",
      " [  0   0  30 107  51   4   0]\n",
      " [  0   0   7  18   8   2   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 442.\n"
     ]
    }
   ],
   "source": [
    "#knn classification taking features that seem to be strong all around quality indicators\n",
    "X = X_initial[ ['chlorides', 'residual sugar'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "ks = [2,3,4,5,6,7]\n",
    "\n",
    "for k in ks:    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"For a k value = \" + str(k) + \" : \")\n",
    "    print(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))\n",
    "    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best knn classification so far is a 7 neighbor classifier on the 'alcohol' and 'density' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   2   2   0   1   0]\n",
      " [  0   0  14  11   0   0   0]\n",
      " [  0   0 138 151   2   0   0]\n",
      " [  1   0  91 320  20   0   0]\n",
      " [  0   0  18 138  36   0   0]\n",
      " [  0   0   2  21  12   0   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   2   3   0   0   0]\n",
      " [  0   0   8  16   1   0   0]\n",
      " [  0   0  88 202   1   0   0]\n",
      " [  0   0  74 355   3   0   0]\n",
      " [  0   0  17 164  11   0   0]\n",
      " [  0   0   2  29   4   0   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 454.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   2   3   0   0   0]\n",
      " [  0   0   7  17   1   0   0]\n",
      " [  0   0  84 205   2   0   0]\n",
      " [  0   0  75 354   3   0   0]\n",
      " [  0   0  17 170   5   0   0]\n",
      " [  0   0   2  32   1   0   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 443.\n",
      "[[  1   0   2   2   0   0   0]\n",
      " [  0   0   7  18   0   0   0]\n",
      " [  0   0  88 202   1   0   0]\n",
      " [  0   0  75 356   1   0   0]\n",
      " [  0   0  18 170   4   0   0]\n",
      " [  0   0   2  33   0   0   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Sum of the diagonals is: 449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "solvers = ['newton-cg', 'sag', 'saga', 'lbfgs' ]\n",
    "for solver in solvers:\n",
    "    mulnom_clf = linear_model.LogisticRegression(multi_class='multinomial', solver=solver)\n",
    "    mulnom_clf.fit(X_train, y_train)\n",
    "    y_pred_mulnom = mulnom_clf.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred_mulnom, labels=[3, 4, 5, 6, 7, 8, 9]))\n",
    "    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred_mulnom, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0   0   2   0   0]\n",
      " [  0  16   0   0  11   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   3   0   0 176   0   0]\n",
      " [  0   0   0   0  39   0   0]\n",
      " [  0   0   0   0   1   0   0]]\n",
      "Sum of the diagonals is: 192.\n",
      "[[  0   0   0   0   3   0   0]\n",
      " [  0   5   0   0  22   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   2   0   0 177   0   0]\n",
      " [  0   0   0   0  39   0   0]\n",
      " [  0   0   0   0   1   0   0]]\n",
      "Sum of the diagonals is: 182.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\ramka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   3   0   0]\n",
      " [  0   5   0   0  22   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   2   0   0 177   0   0]\n",
      " [  0   0   0   0  39   0   0]\n",
      " [  0   0   0   0   1   0   0]]\n",
      "Sum of the diagonals is: 182.\n",
      "[[  0   1   0   0   2   0   0]\n",
      " [  0   9   0   0  18   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   2   0   0 177   0   0]\n",
      " [  0   0   0   0  39   0   0]\n",
      " [  0   0   0   0   1   0   0]]\n",
      "Sum of the diagonals is: 186.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramka\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "high_and_low = high_quality.append(low_quality)\n",
    "X_initial = high_and_low.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity'] ]\n",
    "y = high_and_low['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "solvers = ['newton-cg', 'sag', 'saga', 'lbfgs' ]\n",
    "for solver in solvers:\n",
    "    mulnom_clf = linear_model.LogisticRegression(multi_class='multinomial', solver=solver)\n",
    "    mulnom_clf.fit(X_train, y_train)\n",
    "    y_pred_mulnom = mulnom_clf.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred_mulnom, labels=[3, 4, 5, 6, 7, 8, 9]))\n",
    "    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred_mulnom, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_initial = white_wine.drop([\\'quality\\'], axis=1)\\nX = X_initial[ [\\'alcohol\\', \\'density\\', \\'total sulfur dioxide\\', \\'free sulfur dioxide\\', \\'volatile acidity\\', \\'fixed acidity\\'] ]\\ny = white_wine[\\'quality\\']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nestimatators = [10, 20,  30, 40, 50, 60, 70, 80, 90, 100 ]\\nfor estimator in estimatators:\\n    grad_boost_clf = sklearn.ensemble.GradientBoostingClassifier(n_estimators=estimator)\\n    grad_boost_clf.fit(X_train, y_train)\\n    y_pred_grad_boost = grad_boost_clf.predict(X_test)\\n    print(\"For n_estimators = \" + str(estimator) + \".\")\\n    print(confusion_matrix(y_test, y_pred_grad_boost, labels=[3, 4, 5, 6, 7, 8, 9]))\\n    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred_grad_boost, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")\\n    print(\"---------------------------------------------------------------------------------------------------------\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimatators = [10, 20,  30, 40, 50, 60, 70, 80, 90, 100 ]\n",
    "for estimator in estimatators:\n",
    "    grad_boost_clf = sklearn.ensemble.GradientBoostingClassifier(n_estimators=estimator)\n",
    "    grad_boost_clf.fit(X_train, y_train)\n",
    "    y_pred_grad_boost = grad_boost_clf.predict(X_test)\n",
    "    print(\"For n_estimators = \" + str(estimator) + \".\")\n",
    "    print(confusion_matrix(y_test, y_pred_grad_boost, labels=[3, 4, 5, 6, 7, 8, 9]))\n",
    "    print(\"Sum of the diagonals is: \" + str(np.trace(confusion_matrix(y_test, y_pred_grad_boost, labels=[3, 4, 5, 6, 7, 8, 9]))) + \".\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forrest has perfromed the best out of all the classifiers. I will continue to use random forrest and tweak it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimators = list(range(50, 3000, 100))\n",
    "points = {}\n",
    "for estimator in estimators:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=estimator)\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    points[estimator] = ( np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9])) )/980"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the more features I have the better the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(points.keys(), points.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimators = list(range(50, 3000, 100))\n",
    "points_high_indicators = {}\n",
    "for estimator in estimators:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=estimator)\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    points_high_indicators[estimator] = ( np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9])) )/980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(points_high_indicators.keys(), points_high_indicators.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['free sulfur dioxide', 'volatile acidity', 'fixed acidity'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimators = list(range(50, 3000, 100))\n",
    "points_low_indicators = {}\n",
    "for estimator in estimators:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=estimator)\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    points_low_indicators[estimator] = ( np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9])) )/980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(points_low_indicators.keys(), points_low_indicators.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['chlorides', 'residual sugar'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimators = list(range(50, 3000, 100))\n",
    "points_three_indicators = {}\n",
    "for estimator in estimators:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=estimator)\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    points_three_indicators[estimator] = ( np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9])) )/980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(points_three_indicators.keys(), points_three_indicators.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity', 'chlorides', 'residual sugar'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimators = list(range(50, 3000, 100))\n",
    "points_all = {}\n",
    "for estimator in estimators:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=estimator)\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    points_all[estimator] = ( np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9])) )/980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(points_all.keys(), points_all.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1150 estimators seems to be the optimal estimator amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6918367346938775"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_all[1150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_feature parameter 'sqrt' we have score 0.6846938775510204\n",
      "For max_feature parameter 'log2' we have score 0.6795918367346939\n",
      "For max_feature parameter 'auto' we have score 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "#max_feature parameter tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity', 'chlorides', 'residual sugar'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "parameters = ['sqrt', 'log2', 'auto']\n",
    "for param in parameters:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=1150, max_features=param)\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    print( \"For max_feature parameter '\" + str(param) + \"' we have score \" + str(np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9]))/980) )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best max_feature parameter is 'auto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For criterion parameter 'gini' we have score 0.6816326530612244\n",
      "For criterion parameter 'entropy' we have score 0.6887755102040817\n"
     ]
    }
   ],
   "source": [
    "#criterion parameter tuning\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity', 'chlorides', 'residual sugar'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "parameters = ['gini', 'entropy']\n",
    "for param in parameters:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=1150, max_features='auto', criterion=param )\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    print( \"For criterion parameter '\" + str(param) + \"' we have score \" + str(np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9]))/980) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best criterion parameter is 'entropy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For bootstrap parameter 'True' we have score 0.6877551020408164\n",
      "For bootstrap parameter 'False' we have score 0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "#bootstrap  parameter tuning\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity', 'chlorides', 'residual sugar'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "parameters = [True, False]\n",
    "for param in parameters:\n",
    "    ran_fores_clf = RandomForestClassifier(n_estimators=1150, max_features='auto', criterion='entropy', bootstrap=param )\n",
    "    ran_fores_clf.fit(X_train, y_train)\n",
    "    y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "    print( \"For bootstrap parameter '\" + str(param) + \"' we have score \" + str(np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9]))/980) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best bootstrap parameter is 'True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My best classifier yeilds an accuracy of 0.6846938775510204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_initial = white_wine.drop(['quality'], axis=1)\n",
    "X = X_initial[ ['alcohol', 'density', 'total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'fixed acidity', 'chlorides', 'residual sugar'] ]\n",
    "y = white_wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ran_fores_clf = RandomForestClassifier(n_estimators=1150, max_features='auto', criterion='entropy', bootstrap=True )\n",
    "ran_fores_clf.fit(X_train, y_train)\n",
    "y_pred_ran_fores = ran_fores_clf.predict(X_test)\n",
    "print( \"My best classifier yeilds an accuracy of \" + str(np.trace(confusion_matrix(y_test, y_pred_ran_fores, labels=[3, 4, 5, 6, 7, 8, 9]))/980) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
